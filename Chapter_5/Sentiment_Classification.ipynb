{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import imdb\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.ops import rnn,rnn_cell\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.16.2\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(np.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train,y_train),(X_test,y_test) = imdb.load_data(path=\"imdb_full.pkl\",\n",
    "                                                  num_words=None,\n",
    "                                                  skip_top=0,\n",
    "                                                  maxlen=None,\n",
    "                                                  seed=113,\n",
    "                                                  start_char=1,\n",
    "                                                  oov_char=2,\n",
    "                                                  index_from=3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = [item for sublist in X_train for item in sublist] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = len(set(t)) + 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fb35b818a90>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = [len(x) for x in X_train]\n",
    "plt.plot(a) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length  = 200 \n",
    "x_filter = []\n",
    "y_filter = []\n",
    "\n",
    "for i in range(len(X_train)):\n",
    "    if len(X_train[i]) < max_length:\n",
    "        a = len(X_train[i])\n",
    "        X_train[i] = X_train[i] + [0] * (max_length - a)\n",
    "        x_filter.append(X_train[i])\n",
    "        y_filter.append(y_train[i])\n",
    "    elif len(X_train[i]) > max_length:\n",
    "        X_train[i] = X_train[i][0:max_length] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# declaring the hyper params\n",
    "embedding_size = 100\n",
    "n_hidden = 200 \n",
    "learning_rate = 0.06 \n",
    "training_iters = 100000 \n",
    "batch_size = 32 \n",
    "beta = 0.0001 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = max_length\n",
    "n_classes = 2 \n",
    "da = 350 \n",
    "r =30 \n",
    "display_step = 10 \n",
    "hidden_units = 3000 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.asarray(pd.get_dummies(y_filter))\n",
    "X_train = np.asarray([np.asarray(g) for g in x_filter]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs_path = './recent_logs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataIterator:\n",
    "    def __init__(self,data1,data2,batch_size):\n",
    "        self.data1 = data1\n",
    "        self.data2 = data2\n",
    "        self.batch_size = batch_size\n",
    "        self.iter = self.make_random_iter()\n",
    "        \n",
    "    def next_batch(self):\n",
    "        try:\n",
    "            idxs = next(self.iter)\n",
    "        except StopIteration:\n",
    "            self.iter = self.make_random_iter()\n",
    "            idxs = next(self.iter)\n",
    "        X = [self.data1[i] for i in idxs]\n",
    "        Y = [self.data2[i] for i in idxs]\n",
    "        \n",
    "        X = np.array(X)\n",
    "        Y = np.array(Y)\n",
    "        return X,Y\n",
    "    \n",
    "    def make_random_iter(self):\n",
    "        splits = np.arange(self.batch_size,len(self.data1),self.batch_size)\n",
    "        it = np.split(np.random.permutation(range(len(self.data1))),splits)[:-1]\n",
    "        return iter(it) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"weights\"):\n",
    "    Win = tf.Variable(tf.random_uniform([n_hidden*r,hidden_units],-1/np.sqrt(n_hidden),1/np.sqrt(n_hidden)),name='W-input')\n",
    "    Wout = tf.Variable(tf.random_uniform([hidden_units,n_classes],-1/np.sqrt(hidden_units),1/np.sqrt(hidden_units)),name='W-out')\n",
    "    Ws1 = tf.Variable(tf.random_uniform([da,n_hidden],1/np.sqrt(da)),name='Ws1')\n",
    "    Ws2 = tf.Variable(tf.random_uniform([r,da],-1/np.sqrt(r)),name='Ws2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('biases'):\n",
    "    biasesout = tf.Variable(tf.random_normal([n_classes]),name='biases-out')\n",
    "    biasesin = tf.Variable(tf.random_normal([hidden_units]),name='biases-in')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('input'):\n",
    "    x = tf.placeholder(\"int32\",[32,max_length],name='x-input')\n",
    "    y = tf.placeholder(\"int32\",[32,2],name='y-input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('embedding'):\n",
    "    embeddings = tf.Variable(tf.random_uniform([vocabulary,embedding_size],-1,1),name='embeddings')\n",
    "    embed = tf.nn.embedding_lookup(embeddings,x) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def length(sequence):\n",
    "    used = tf.sign(tf.reduce_max(tf.abs(sequence),reduction_indices=2))\n",
    "    \n",
    "    length = tf.reduce_sum(used,reduction_indices=1)\n",
    "    length = tf.cast(length,tf.int32)\n",
    "    return length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope('forward',reuse=True):\n",
    "    lstm_fw_cell = tf.nn.rnn_cell.LSTMCell(n_hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('model'):\n",
    "    outputs,states = rnn.dynamic_rnn(lstm_fw_cell,embed,sequence_length=length(embed),dtype=tf.float32,time_major=False)\n",
    "    h = tf.nn.tanh(tf.transpose(tf.reshape(tf.matmul(Ws1,tf.reshape(outputs,[n_hidden,batch_size*n_steps])),\n",
    "                                          [da,batch_size,n_steps]),[1,0,2]))\n",
    "    a = tf.reshape(tf.matmul(Ws2,tf.reshape(h,[da,batch_size*n_steps])),[batch_size,r,n_steps])\n",
    "    def fn3(a,x):\n",
    "        return tf.nn.softmax(x)\n",
    "    h3 = tf.scan(fn3,a) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('flattening'):\n",
    "    h4 = tf.matmul(h3,outputs)\n",
    "    last = tf.reshape(h4,[-1,r*n_hidden]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('MLP'):\n",
    "    tf.nn.dropout(last,.5,noise_shape=None,seed=None,name=None)\n",
    "    pred1 = tf.nn.sigmoid(tf.matmul(last,Win)+biasesin)\n",
    "    pred = tf.matmul(pred1,Wout) + biasesout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-25-42ef32ec4ee7>:2: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with tf.name_scope('cross'):\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred,labels=y)+beta*tf.nn.l2_loss(Ws2))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('train'):\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "    gvs = optimizer.compute_gradients(cost)\n",
    "    capped_gvs = [(tf.clip_by_norm(grad,0.5),var) for grad,var in gvs]\n",
    "    optimizer.apply_gradients(capped_gvs)\n",
    "    optimized = optimizer.minimize(cost) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('Accuracy'):\n",
    "    correct_pred = tf.equal(tf.argmax(pred,1),tf.argmax(y,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred,tf.float32)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'accuracy_1:0' shape=() dtype=string>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.summary.scalar(\"cost\",cost)\n",
    "tf.summary.scalar(\"accuracy\",accuracy) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_op = tf.summary.merge_all() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter = DataIterator(X_train,y_train,batch_size)\n",
    "init = tf.global_variables_initializer() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 64, Minibatch Loss= 17.535246, Training Accuracy= 50.00%\n",
      "Iter 384, Minibatch Loss= 44.965031, Training Accuracy= 50.00%\n",
      "Iter 704, Minibatch Loss= 33.932579, Training Accuracy= 53.12%\n",
      "Iter 1024, Minibatch Loss= 8.257021, Training Accuracy= 56.25%\n",
      "Iter 1344, Minibatch Loss= 24.839247, Training Accuracy= 37.50%\n",
      "Iter 1664, Minibatch Loss= 5.613566, Training Accuracy= 56.25%\n",
      "Iter 1984, Minibatch Loss= 20.405418, Training Accuracy= 46.88%\n",
      "Iter 2304, Minibatch Loss= 5.527768, Training Accuracy= 56.25%\n",
      "Iter 2624, Minibatch Loss= 18.573048, Training Accuracy= 46.88%\n",
      "Iter 2944, Minibatch Loss= 29.602596, Training Accuracy= 46.88%\n",
      "Iter 3264, Minibatch Loss= 34.473885, Training Accuracy= 43.75%\n",
      "Iter 3584, Minibatch Loss= 13.020053, Training Accuracy= 56.25%\n",
      "Iter 3904, Minibatch Loss= 7.984556, Training Accuracy= 53.12%\n",
      "Iter 4224, Minibatch Loss= 5.199084, Training Accuracy= 53.12%\n",
      "Iter 4544, Minibatch Loss= 7.820098, Training Accuracy= 46.88%\n",
      "Iter 4864, Minibatch Loss= 3.158295, Training Accuracy= 46.88%\n",
      "Iter 5184, Minibatch Loss= 8.077681, Training Accuracy= 75.00%\n",
      "Iter 5504, Minibatch Loss= 2.545912, Training Accuracy= 43.75%\n",
      "Iter 5824, Minibatch Loss= 15.499278, Training Accuracy= 34.38%\n",
      "Iter 6144, Minibatch Loss= 15.008638, Training Accuracy= 43.75%\n",
      "Iter 6464, Minibatch Loss= 10.098028, Training Accuracy= 62.50%\n",
      "Iter 6784, Minibatch Loss= 10.408873, Training Accuracy= 65.62%\n",
      "Iter 7104, Minibatch Loss= 28.802982, Training Accuracy= 46.88%\n",
      "Iter 7424, Minibatch Loss= 39.565514, Training Accuracy= 43.75%\n",
      "Iter 7744, Minibatch Loss= 27.216726, Training Accuracy= 56.25%\n",
      "Iter 8064, Minibatch Loss= 15.015453, Training Accuracy= 62.50%\n",
      "Iter 8384, Minibatch Loss= 5.944937, Training Accuracy= 56.25%\n",
      "Iter 8704, Minibatch Loss= 6.568155, Training Accuracy= 40.62%\n",
      "Iter 9024, Minibatch Loss= 11.824574, Training Accuracy= 62.50%\n",
      "Iter 9344, Minibatch Loss= 17.876730, Training Accuracy= 56.25%\n",
      "Iter 9664, Minibatch Loss= 4.434173, Training Accuracy= 56.25%\n",
      "Iter 9984, Minibatch Loss= 15.529695, Training Accuracy= 46.88%\n",
      "Iter 10304, Minibatch Loss= 6.289638, Training Accuracy= 43.75%\n",
      "Iter 10624, Minibatch Loss= 13.742834, Training Accuracy= 46.88%\n",
      "Iter 10944, Minibatch Loss= 9.564969, Training Accuracy= 68.75%\n",
      "Iter 11264, Minibatch Loss= 7.536999, Training Accuracy= 43.75%\n",
      "Iter 11584, Minibatch Loss= 5.322386, Training Accuracy= 50.00%\n",
      "Iter 11904, Minibatch Loss= 20.951012, Training Accuracy= 59.38%\n",
      "Iter 12224, Minibatch Loss= 26.394848, Training Accuracy= 50.00%\n",
      "Iter 12544, Minibatch Loss= 7.341204, Training Accuracy= 53.12%\n",
      "Iter 12864, Minibatch Loss= 1.652851, Training Accuracy= 62.50%\n",
      "Iter 13184, Minibatch Loss= 5.279025, Training Accuracy= 56.25%\n",
      "Iter 13504, Minibatch Loss= 11.769241, Training Accuracy= 65.62%\n",
      "Iter 13824, Minibatch Loss= 17.502899, Training Accuracy= 53.12%\n",
      "Iter 14144, Minibatch Loss= 27.380539, Training Accuracy= 59.38%\n",
      "Iter 14464, Minibatch Loss= 15.037024, Training Accuracy= 53.12%\n",
      "Iter 14784, Minibatch Loss= 1.510816, Training Accuracy= 50.00%\n",
      "Iter 15104, Minibatch Loss= 3.939610, Training Accuracy= 53.12%\n",
      "Iter 15424, Minibatch Loss= 8.641228, Training Accuracy= 53.12%\n",
      "Iter 15744, Minibatch Loss= 27.737640, Training Accuracy= 62.50%\n",
      "Iter 16064, Minibatch Loss= 20.450687, Training Accuracy= 43.75%\n",
      "Iter 16384, Minibatch Loss= 17.899136, Training Accuracy= 40.62%\n",
      "Iter 16704, Minibatch Loss= 9.890913, Training Accuracy= 56.25%\n",
      "Iter 17024, Minibatch Loss= 20.006128, Training Accuracy= 50.00%\n",
      "Iter 17344, Minibatch Loss= 36.284271, Training Accuracy= 34.38%\n",
      "Iter 17664, Minibatch Loss= 23.424923, Training Accuracy= 50.00%\n",
      "Iter 17984, Minibatch Loss= 4.273010, Training Accuracy= 62.50%\n",
      "Iter 18304, Minibatch Loss= 16.397829, Training Accuracy= 46.88%\n",
      "Iter 18624, Minibatch Loss= 9.720943, Training Accuracy= 50.00%\n",
      "Iter 18944, Minibatch Loss= 3.298427, Training Accuracy= 46.88%\n",
      "Iter 19264, Minibatch Loss= 12.753351, Training Accuracy= 59.38%\n",
      "Iter 19584, Minibatch Loss= 6.135378, Training Accuracy= 50.00%\n",
      "Iter 19904, Minibatch Loss= 23.873634, Training Accuracy= 31.25%\n",
      "Iter 20224, Minibatch Loss= 17.907475, Training Accuracy= 56.25%\n",
      "Iter 20544, Minibatch Loss= 3.586796, Training Accuracy= 56.25%\n",
      "Iter 20864, Minibatch Loss= 15.350352, Training Accuracy= 62.50%\n",
      "Iter 21184, Minibatch Loss= 2.391934, Training Accuracy= 34.38%\n",
      "Iter 21504, Minibatch Loss= 6.581500, Training Accuracy= 53.12%\n",
      "Iter 21824, Minibatch Loss= 2.831348, Training Accuracy= 53.12%\n",
      "Iter 22144, Minibatch Loss= 11.903221, Training Accuracy= 43.75%\n",
      "Iter 22464, Minibatch Loss= 4.561800, Training Accuracy= 59.38%\n",
      "Iter 22784, Minibatch Loss= 10.646049, Training Accuracy= 68.75%\n",
      "Iter 23104, Minibatch Loss= 11.574767, Training Accuracy= 56.25%\n",
      "Iter 23424, Minibatch Loss= 15.733418, Training Accuracy= 56.25%\n",
      "Iter 23744, Minibatch Loss= 24.510223, Training Accuracy= 46.88%\n",
      "Iter 24064, Minibatch Loss= 35.189461, Training Accuracy= 46.88%\n",
      "Iter 24384, Minibatch Loss= 35.545097, Training Accuracy= 43.75%\n",
      "Iter 24704, Minibatch Loss= 24.002623, Training Accuracy= 53.12%\n",
      "Iter 25024, Minibatch Loss= 50.622955, Training Accuracy= 43.75%\n",
      "Iter 25344, Minibatch Loss= 3.012216, Training Accuracy= 46.88%\n",
      "Iter 25664, Minibatch Loss= 8.567302, Training Accuracy= 50.00%\n",
      "Iter 25984, Minibatch Loss= 8.242495, Training Accuracy= 53.12%\n",
      "Iter 26304, Minibatch Loss= 8.027637, Training Accuracy= 65.62%\n",
      "Iter 26624, Minibatch Loss= 6.659829, Training Accuracy= 40.62%\n",
      "Iter 26944, Minibatch Loss= 9.651891, Training Accuracy= 46.88%\n",
      "Iter 27264, Minibatch Loss= 3.401053, Training Accuracy= 43.75%\n",
      "Iter 27584, Minibatch Loss= 23.587772, Training Accuracy= 50.00%\n",
      "Iter 27904, Minibatch Loss= 4.485902, Training Accuracy= 50.00%\n",
      "Iter 28224, Minibatch Loss= 13.118986, Training Accuracy= 46.88%\n",
      "Iter 28544, Minibatch Loss= 14.410769, Training Accuracy= 37.50%\n",
      "Iter 28864, Minibatch Loss= 9.023668, Training Accuracy= 43.75%\n",
      "Iter 29184, Minibatch Loss= 12.697077, Training Accuracy= 50.00%\n",
      "Iter 29504, Minibatch Loss= 29.799971, Training Accuracy= 43.75%\n",
      "Iter 29824, Minibatch Loss= 6.904250, Training Accuracy= 59.38%\n",
      "Iter 30144, Minibatch Loss= 6.883192, Training Accuracy= 46.88%\n",
      "Iter 30464, Minibatch Loss= 1.976935, Training Accuracy= 40.62%\n",
      "Iter 30784, Minibatch Loss= 0.779164, Training Accuracy= 43.75%\n",
      "Iter 31104, Minibatch Loss= 2.028672, Training Accuracy= 46.88%\n",
      "Iter 31424, Minibatch Loss= 1.292887, Training Accuracy= 56.25%\n",
      "Iter 31744, Minibatch Loss= 5.400048, Training Accuracy= 43.75%\n",
      "Iter 32064, Minibatch Loss= 14.783754, Training Accuracy= 53.12%\n",
      "Iter 32384, Minibatch Loss= 13.384201, Training Accuracy= 46.88%\n",
      "Iter 32704, Minibatch Loss= 19.228485, Training Accuracy= 46.88%\n",
      "Iter 33024, Minibatch Loss= 16.695820, Training Accuracy= 50.00%\n",
      "Iter 33344, Minibatch Loss= 4.133802, Training Accuracy= 59.38%\n",
      "Iter 33664, Minibatch Loss= 5.863837, Training Accuracy= 65.62%\n",
      "Iter 33984, Minibatch Loss= 32.376442, Training Accuracy= 46.88%\n",
      "Iter 34304, Minibatch Loss= 17.717468, Training Accuracy= 46.88%\n",
      "Iter 34624, Minibatch Loss= 5.300380, Training Accuracy= 53.12%\n",
      "Iter 34944, Minibatch Loss= 35.504848, Training Accuracy= 46.88%\n",
      "Iter 35264, Minibatch Loss= 9.115853, Training Accuracy= 62.50%\n",
      "Iter 35584, Minibatch Loss= 11.998707, Training Accuracy= 43.75%\n",
      "Iter 35904, Minibatch Loss= 0.901166, Training Accuracy= 40.62%\n",
      "Iter 36224, Minibatch Loss= 4.673072, Training Accuracy= 59.38%\n",
      "Iter 36544, Minibatch Loss= 4.419613, Training Accuracy= 65.62%\n",
      "Iter 36864, Minibatch Loss= 23.497288, Training Accuracy= 34.38%\n",
      "Iter 37184, Minibatch Loss= 0.786553, Training Accuracy= 43.75%\n",
      "Iter 37504, Minibatch Loss= 14.852895, Training Accuracy= 40.62%\n",
      "Iter 37824, Minibatch Loss= 12.184511, Training Accuracy= 43.75%\n",
      "Iter 38144, Minibatch Loss= 12.094361, Training Accuracy= 56.25%\n",
      "Iter 38464, Minibatch Loss= 1.622971, Training Accuracy= 40.62%\n",
      "Iter 38784, Minibatch Loss= 17.004318, Training Accuracy= 40.62%\n",
      "Iter 39104, Minibatch Loss= 4.531135, Training Accuracy= 59.38%\n",
      "Iter 39424, Minibatch Loss= 21.023300, Training Accuracy= 40.62%\n",
      "Iter 39744, Minibatch Loss= 32.937202, Training Accuracy= 53.12%\n",
      "Iter 40064, Minibatch Loss= 42.676964, Training Accuracy= 53.12%\n",
      "Iter 40384, Minibatch Loss= 20.642891, Training Accuracy= 43.75%\n",
      "Iter 40704, Minibatch Loss= 21.335934, Training Accuracy= 50.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 41024, Minibatch Loss= 1.193390, Training Accuracy= 56.25%\n",
      "Iter 41344, Minibatch Loss= 11.385191, Training Accuracy= 53.12%\n",
      "Iter 41664, Minibatch Loss= 4.226768, Training Accuracy= 59.38%\n",
      "Iter 41984, Minibatch Loss= 0.744679, Training Accuracy= 43.75%\n",
      "Iter 42304, Minibatch Loss= 8.150616, Training Accuracy= 46.88%\n",
      "Iter 42624, Minibatch Loss= 8.553251, Training Accuracy= 59.38%\n",
      "Iter 42944, Minibatch Loss= 2.573560, Training Accuracy= 53.12%\n",
      "Iter 43264, Minibatch Loss= 14.710289, Training Accuracy= 59.38%\n",
      "Iter 43584, Minibatch Loss= 12.511387, Training Accuracy= 46.88%\n",
      "Iter 43904, Minibatch Loss= 19.932281, Training Accuracy= 59.38%\n",
      "Iter 44224, Minibatch Loss= 5.673762, Training Accuracy= 40.62%\n",
      "Iter 44544, Minibatch Loss= 21.306601, Training Accuracy= 59.38%\n",
      "Iter 44864, Minibatch Loss= 15.287939, Training Accuracy= 53.12%\n",
      "Iter 45184, Minibatch Loss= 0.989928, Training Accuracy= 50.00%\n",
      "Iter 45504, Minibatch Loss= 8.017136, Training Accuracy= 56.25%\n",
      "Iter 45824, Minibatch Loss= 3.185121, Training Accuracy= 43.75%\n",
      "Iter 46144, Minibatch Loss= 9.590856, Training Accuracy= 59.38%\n",
      "Iter 46464, Minibatch Loss= 8.927942, Training Accuracy= 62.50%\n",
      "Iter 46784, Minibatch Loss= 4.653939, Training Accuracy= 37.50%\n",
      "Iter 47104, Minibatch Loss= 24.112816, Training Accuracy= 50.00%\n",
      "Iter 47424, Minibatch Loss= 5.232939, Training Accuracy= 40.62%\n",
      "Iter 47744, Minibatch Loss= 10.318232, Training Accuracy= 50.00%\n",
      "Iter 48064, Minibatch Loss= 47.380692, Training Accuracy= 34.38%\n",
      "Iter 48384, Minibatch Loss= 21.246044, Training Accuracy= 50.00%\n",
      "Iter 48704, Minibatch Loss= 18.910236, Training Accuracy= 56.25%\n",
      "Iter 49024, Minibatch Loss= 5.856133, Training Accuracy= 53.12%\n",
      "Iter 49344, Minibatch Loss= 4.471401, Training Accuracy= 53.12%\n",
      "Iter 49664, Minibatch Loss= 1.758750, Training Accuracy= 46.88%\n",
      "Iter 49984, Minibatch Loss= 9.761005, Training Accuracy= 46.88%\n",
      "Iter 50304, Minibatch Loss= 28.370836, Training Accuracy= 53.12%\n",
      "Iter 50624, Minibatch Loss= 24.993351, Training Accuracy= 53.12%\n",
      "Iter 50944, Minibatch Loss= 26.159306, Training Accuracy= 56.25%\n",
      "Iter 51264, Minibatch Loss= 27.837391, Training Accuracy= 56.25%\n",
      "Iter 51584, Minibatch Loss= 11.137848, Training Accuracy= 59.38%\n",
      "Iter 51904, Minibatch Loss= 9.350665, Training Accuracy= 43.75%\n",
      "Iter 52224, Minibatch Loss= 2.981361, Training Accuracy= 59.38%\n",
      "Iter 52544, Minibatch Loss= 0.670085, Training Accuracy= 62.50%\n",
      "Iter 52864, Minibatch Loss= 4.581450, Training Accuracy= 59.38%\n",
      "Iter 53184, Minibatch Loss= 8.051987, Training Accuracy= 46.88%\n",
      "Iter 53504, Minibatch Loss= 0.799498, Training Accuracy= 50.00%\n",
      "Iter 53824, Minibatch Loss= 8.449479, Training Accuracy= 56.25%\n",
      "Iter 54144, Minibatch Loss= 6.967780, Training Accuracy= 40.62%\n",
      "Iter 54464, Minibatch Loss= 14.270636, Training Accuracy= 46.88%\n",
      "Iter 54784, Minibatch Loss= 6.838820, Training Accuracy= 43.75%\n",
      "Iter 55104, Minibatch Loss= 11.545241, Training Accuracy= 53.12%\n",
      "Iter 55424, Minibatch Loss= 26.647957, Training Accuracy= 50.00%\n",
      "Iter 55744, Minibatch Loss= 15.102031, Training Accuracy= 40.62%\n",
      "Iter 56064, Minibatch Loss= 4.225500, Training Accuracy= 62.50%\n",
      "Iter 56384, Minibatch Loss= 0.719111, Training Accuracy= 59.38%\n",
      "Iter 56704, Minibatch Loss= 19.998671, Training Accuracy= 59.38%\n",
      "Iter 57024, Minibatch Loss= 10.368956, Training Accuracy= 68.75%\n",
      "Iter 57344, Minibatch Loss= 24.879780, Training Accuracy= 56.25%\n",
      "Iter 57664, Minibatch Loss= 35.639915, Training Accuracy= 53.12%\n",
      "Iter 57984, Minibatch Loss= 24.468399, Training Accuracy= 37.50%\n",
      "Iter 58304, Minibatch Loss= 16.577986, Training Accuracy= 53.12%\n",
      "Iter 58624, Minibatch Loss= 26.510420, Training Accuracy= 62.50%\n",
      "Iter 58944, Minibatch Loss= 23.994020, Training Accuracy= 65.62%\n",
      "Iter 59264, Minibatch Loss= 39.914200, Training Accuracy= 46.88%\n",
      "Iter 59584, Minibatch Loss= 24.243626, Training Accuracy= 34.38%\n",
      "Iter 59904, Minibatch Loss= 12.376554, Training Accuracy= 46.88%\n",
      "Iter 60224, Minibatch Loss= 2.861420, Training Accuracy= 43.75%\n",
      "Iter 60544, Minibatch Loss= 2.680322, Training Accuracy= 53.12%\n",
      "Iter 60864, Minibatch Loss= 3.465962, Training Accuracy= 50.00%\n",
      "Iter 61184, Minibatch Loss= 5.116811, Training Accuracy= 50.00%\n",
      "Iter 61504, Minibatch Loss= 0.735885, Training Accuracy= 34.38%\n",
      "Iter 61824, Minibatch Loss= 13.879095, Training Accuracy= 40.62%\n",
      "Iter 62144, Minibatch Loss= 2.323737, Training Accuracy= 53.12%\n",
      "Iter 62464, Minibatch Loss= 1.360445, Training Accuracy= 40.62%\n",
      "Iter 62784, Minibatch Loss= 21.506563, Training Accuracy= 59.38%\n",
      "Iter 63104, Minibatch Loss= 10.718124, Training Accuracy= 56.25%\n",
      "Iter 63424, Minibatch Loss= 0.815481, Training Accuracy= 50.00%\n",
      "Iter 63744, Minibatch Loss= 11.267294, Training Accuracy= 50.00%\n",
      "Iter 64064, Minibatch Loss= 7.477906, Training Accuracy= 46.88%\n",
      "Iter 64384, Minibatch Loss= 2.908692, Training Accuracy= 50.00%\n",
      "Iter 64704, Minibatch Loss= 0.882892, Training Accuracy= 56.25%\n",
      "Iter 65024, Minibatch Loss= 1.846676, Training Accuracy= 34.38%\n",
      "Iter 65344, Minibatch Loss= 0.793009, Training Accuracy= 28.12%\n",
      "Iter 65664, Minibatch Loss= 5.298957, Training Accuracy= 62.50%\n",
      "Iter 65984, Minibatch Loss= 13.743422, Training Accuracy= 56.25%\n",
      "Iter 66304, Minibatch Loss= 0.706472, Training Accuracy= 56.25%\n",
      "Iter 66624, Minibatch Loss= 1.377787, Training Accuracy= 62.50%\n",
      "Iter 66944, Minibatch Loss= 16.070414, Training Accuracy= 46.88%\n",
      "Iter 67264, Minibatch Loss= 8.570965, Training Accuracy= 53.12%\n",
      "Iter 67584, Minibatch Loss= 11.958618, Training Accuracy= 46.88%\n",
      "Iter 67904, Minibatch Loss= 4.294238, Training Accuracy= 56.25%\n",
      "Iter 68224, Minibatch Loss= 9.325254, Training Accuracy= 53.12%\n",
      "Iter 68544, Minibatch Loss= 5.129751, Training Accuracy= 50.00%\n",
      "Iter 68864, Minibatch Loss= 11.694201, Training Accuracy= 37.50%\n",
      "Iter 69184, Minibatch Loss= 2.073716, Training Accuracy= 50.00%\n",
      "Iter 69504, Minibatch Loss= 10.240929, Training Accuracy= 53.12%\n",
      "Iter 69824, Minibatch Loss= 14.972909, Training Accuracy= 56.25%\n",
      "Iter 70144, Minibatch Loss= 8.086793, Training Accuracy= 59.38%\n",
      "Iter 70464, Minibatch Loss= 16.780817, Training Accuracy= 56.25%\n",
      "Iter 70784, Minibatch Loss= 3.697155, Training Accuracy= 65.62%\n",
      "Iter 71104, Minibatch Loss= 15.606598, Training Accuracy= 59.38%\n",
      "Iter 71424, Minibatch Loss= 8.549047, Training Accuracy= 50.00%\n",
      "Iter 71744, Minibatch Loss= 9.839442, Training Accuracy= 43.75%\n",
      "Iter 72064, Minibatch Loss= 0.787000, Training Accuracy= 46.88%\n",
      "Iter 72384, Minibatch Loss= 10.659541, Training Accuracy= 43.75%\n",
      "Iter 72704, Minibatch Loss= 1.442110, Training Accuracy= 56.25%\n",
      "Iter 73024, Minibatch Loss= 7.789529, Training Accuracy= 59.38%\n",
      "Iter 73344, Minibatch Loss= 16.181517, Training Accuracy= 40.62%\n",
      "Iter 73664, Minibatch Loss= 25.596169, Training Accuracy= 40.62%\n",
      "Iter 73984, Minibatch Loss= 15.032666, Training Accuracy= 40.62%\n",
      "Iter 74304, Minibatch Loss= 2.751857, Training Accuracy= 50.00%\n",
      "Iter 74624, Minibatch Loss= 2.503513, Training Accuracy= 56.25%\n",
      "Iter 74944, Minibatch Loss= 12.954187, Training Accuracy= 56.25%\n",
      "Iter 75264, Minibatch Loss= 11.229446, Training Accuracy= 56.25%\n",
      "Iter 75584, Minibatch Loss= 8.678778, Training Accuracy= 46.88%\n",
      "Iter 75904, Minibatch Loss= 6.786606, Training Accuracy= 53.12%\n",
      "Iter 76224, Minibatch Loss= 6.384160, Training Accuracy= 43.75%\n",
      "Iter 76544, Minibatch Loss= 15.855406, Training Accuracy= 40.62%\n",
      "Iter 76864, Minibatch Loss= 2.283838, Training Accuracy= 46.88%\n",
      "Iter 77184, Minibatch Loss= 1.555531, Training Accuracy= 59.38%\n",
      "Iter 77504, Minibatch Loss= 3.508013, Training Accuracy= 43.75%\n",
      "Iter 77824, Minibatch Loss= 17.221874, Training Accuracy= 37.50%\n",
      "Iter 78144, Minibatch Loss= 4.668246, Training Accuracy= 53.12%\n",
      "Iter 78464, Minibatch Loss= 3.092018, Training Accuracy= 65.62%\n",
      "Iter 78784, Minibatch Loss= 8.325315, Training Accuracy= 59.38%\n",
      "Iter 79104, Minibatch Loss= 8.692702, Training Accuracy= 53.12%\n",
      "Iter 79424, Minibatch Loss= 17.969006, Training Accuracy= 53.12%\n",
      "Iter 79744, Minibatch Loss= 11.446769, Training Accuracy= 53.12%\n",
      "Iter 80064, Minibatch Loss= 19.381599, Training Accuracy= 46.88%\n",
      "Iter 80384, Minibatch Loss= 5.583399, Training Accuracy= 40.62%\n",
      "Iter 80704, Minibatch Loss= 23.031937, Training Accuracy= 59.38%\n",
      "Iter 81024, Minibatch Loss= 22.124565, Training Accuracy= 46.88%\n",
      "Iter 81344, Minibatch Loss= 19.904331, Training Accuracy= 56.25%\n",
      "Iter 81664, Minibatch Loss= 10.737139, Training Accuracy= 40.62%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 81984, Minibatch Loss= 11.568510, Training Accuracy= 50.00%\n",
      "Iter 82304, Minibatch Loss= 17.280609, Training Accuracy= 50.00%\n",
      "Iter 82624, Minibatch Loss= 6.370775, Training Accuracy= 50.00%\n",
      "Iter 82944, Minibatch Loss= 5.910687, Training Accuracy= 53.12%\n",
      "Iter 83264, Minibatch Loss= 3.990377, Training Accuracy= 65.62%\n",
      "Iter 83584, Minibatch Loss= 13.615839, Training Accuracy= 65.62%\n",
      "Iter 83904, Minibatch Loss= 20.126209, Training Accuracy= 59.38%\n",
      "Iter 84224, Minibatch Loss= 20.488033, Training Accuracy= 50.00%\n",
      "Iter 84544, Minibatch Loss= 14.598964, Training Accuracy= 50.00%\n",
      "Iter 84864, Minibatch Loss= 0.943670, Training Accuracy= 53.12%\n",
      "Iter 85184, Minibatch Loss= 11.788865, Training Accuracy= 53.12%\n",
      "Iter 85504, Minibatch Loss= 5.947331, Training Accuracy= 62.50%\n",
      "Iter 85824, Minibatch Loss= 14.755472, Training Accuracy= 50.00%\n",
      "Iter 86144, Minibatch Loss= 5.578073, Training Accuracy= 53.12%\n",
      "Iter 86464, Minibatch Loss= 18.994911, Training Accuracy= 50.00%\n",
      "Iter 86784, Minibatch Loss= 19.760405, Training Accuracy= 43.75%\n",
      "Iter 87104, Minibatch Loss= 5.989168, Training Accuracy= 46.88%\n",
      "Iter 87424, Minibatch Loss= 0.777365, Training Accuracy= 59.38%\n",
      "Iter 87744, Minibatch Loss= 2.930994, Training Accuracy= 37.50%\n",
      "Iter 88064, Minibatch Loss= 1.649444, Training Accuracy= 62.50%\n",
      "Iter 88384, Minibatch Loss= 11.847616, Training Accuracy= 40.62%\n",
      "Iter 88704, Minibatch Loss= 18.641899, Training Accuracy= 46.88%\n",
      "Iter 89024, Minibatch Loss= 1.931029, Training Accuracy= 68.75%\n",
      "Iter 89344, Minibatch Loss= 2.899383, Training Accuracy= 40.62%\n",
      "Iter 89664, Minibatch Loss= 2.929244, Training Accuracy= 59.38%\n",
      "Iter 89984, Minibatch Loss= 1.114542, Training Accuracy= 62.50%\n",
      "Iter 90304, Minibatch Loss= 5.184703, Training Accuracy= 59.38%\n",
      "Iter 90624, Minibatch Loss= 3.064873, Training Accuracy= 56.25%\n",
      "Iter 90944, Minibatch Loss= 16.231632, Training Accuracy= 46.88%\n",
      "Iter 91264, Minibatch Loss= 2.165925, Training Accuracy= 37.50%\n",
      "Iter 91584, Minibatch Loss= 3.634693, Training Accuracy= 56.25%\n",
      "Iter 91904, Minibatch Loss= 0.778957, Training Accuracy= 43.75%\n",
      "Iter 92224, Minibatch Loss= 19.335743, Training Accuracy= 50.00%\n",
      "Iter 92544, Minibatch Loss= 0.629092, Training Accuracy= 75.00%\n",
      "Iter 92864, Minibatch Loss= 26.856632, Training Accuracy= 50.00%\n",
      "Iter 93184, Minibatch Loss= 5.364766, Training Accuracy= 56.25%\n",
      "Iter 93504, Minibatch Loss= 13.929726, Training Accuracy= 56.25%\n",
      "Iter 93824, Minibatch Loss= 13.929771, Training Accuracy= 56.25%\n",
      "Iter 94144, Minibatch Loss= 16.579115, Training Accuracy= 46.88%\n",
      "Iter 94464, Minibatch Loss= 5.053478, Training Accuracy= 50.00%\n",
      "Iter 94784, Minibatch Loss= 3.104481, Training Accuracy= 59.38%\n",
      "Iter 95104, Minibatch Loss= 1.747122, Training Accuracy= 59.38%\n",
      "Iter 95424, Minibatch Loss= 5.320297, Training Accuracy= 43.75%\n",
      "Iter 95744, Minibatch Loss= 9.149046, Training Accuracy= 59.38%\n",
      "Iter 96064, Minibatch Loss= 1.544008, Training Accuracy= 50.00%\n",
      "Iter 96384, Minibatch Loss= 7.699858, Training Accuracy= 50.00%\n",
      "Iter 96704, Minibatch Loss= 5.718311, Training Accuracy= 53.12%\n",
      "Iter 97024, Minibatch Loss= 6.537544, Training Accuracy= 53.12%\n",
      "Iter 97344, Minibatch Loss= 5.513936, Training Accuracy= 56.25%\n",
      "Iter 97664, Minibatch Loss= 2.005014, Training Accuracy= 59.38%\n",
      "Iter 97984, Minibatch Loss= 13.117681, Training Accuracy= 56.25%\n",
      "Iter 98304, Minibatch Loss= 5.890246, Training Accuracy= 68.75%\n",
      "Iter 98624, Minibatch Loss= 0.715613, Training Accuracy= 37.50%\n",
      "Iter 98944, Minibatch Loss= 9.092052, Training Accuracy= 43.75%\n",
      "Iter 99264, Minibatch Loss= 22.755630, Training Accuracy= 56.25%\n",
      "Iter 99584, Minibatch Loss= 11.990618, Training Accuracy= 40.62%\n",
      "Iter 99904, Minibatch Loss= 3.137798, Training Accuracy= 46.88%\n",
      "Optimization Finished!\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    writer = tf.summary.FileWriter(logs_path,graph=tf.get_default_graph())\n",
    "    step = 1 \n",
    "    \n",
    "    while step * batch_size < training_iters:\n",
    "        batch_x,batch_y = train_iter.next_batch()\n",
    "        sess.run(optimized,feed_dict={x:batch_x,y:batch_y})\n",
    "        \n",
    "        summary = sess.run(summary_op,feed_dict={x:batch_x,y:batch_y})\n",
    "        \n",
    "        writer.add_summary(summary,step * batch_size)\n",
    "        \n",
    "        if step % display_step == 2:\n",
    "            acc = sess.run(accuracy,feed_dict={x:batch_x,y:batch_y})\n",
    "            \n",
    "            loss = sess.run(cost, feed_dict= {x:batch_x,y:batch_y})\n",
    "            print(\"Iter \"+str(step*batch_size) + \\\n",
    "                  \", Minibatch Loss= \" + \"{:.6f}\".format(loss) + \\\n",
    "                  \", Training Accuracy= \"+ \"{:.2f}\".format(acc*100) + \"%\")\n",
    "        step += 1 \n",
    "    print(\"Optimization Finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
